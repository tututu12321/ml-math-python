import numpy as np
import matplotlib.pyplot as plt
from sklearn.gaussian_process import GaussianProcessRegressor
from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C

# 正弦波の関数（真の関数）
def true_function(x):
    return np.sin(x)

# トレーニングデータ（ノイズとバイアスあり）
np.random.seed(42)
X_train = np.array([1, 3, 5, 6, 8]).reshape(-1, 1)
y_train = true_function(X_train).ravel() + 0.1 * np.random.randn(len(X_train)) + 0.2  # ノイズとバイアスを加える

# テストデータ
X_test = np.linspace(0, 10, 1000).reshape(-1, 1)

# カーネルの定義（定数カーネルとRBFカーネルの組み合わせ）
kernel = C(1.0, (1e-4, 1e1)) * RBF(1.0, (1e-4, 1e1))

# ガウス過程回帰器のインスタンス作成
gp = GaussianProcessRegressor(kernel=kernel, n_restarts_optimizer=10)

# トレーニングデータを使ってモデルをフィット
gp.fit(X_train, y_train)

# 予測
y_pred, sigma = gp.predict(X_test, return_std=True)

# 結果のプロット
plt.figure(figsize=(10, 6))
plt.plot(X_test, true_function(X_test), 'r:', label='True function')
plt.errorbar(X_train, y_train, 0.1, fmt='r.', markersize=10, label='Training points (with noise and bias)')
plt.plot(X_test, y_pred, 'b-', label='Prediction')
plt.fill_between(X_test.ravel(), y_pred - sigma, y_pred + sigma, alpha=0.2, color='blue', label='Uncertainty')
plt.xlabel('Input')
plt.ylabel('Output')
plt.title('Gaussian Process Regression with Noisy and Biased Data')
plt.legend()
plt.show()
