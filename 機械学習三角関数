import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from joblib import Parallel, delayed
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.optimizers import Adam

# ---- データの生成 ----
np.random.seed(0)
X = np.linspace(-2 * np.pi, 2 * np.pi, 1000).reshape(-1, 1)  # 入力 (サンプリング)
y = np.sin(X)  # 出力 (sin関数)

# 訓練データとテストデータの分割
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# ---- モデル構築関数 ----
def create_model():
    model = Sequential([
        Dense(10, activation='tanh', input_shape=(1,)),  # 1層目 (入力層)
        Dense(10, activation='tanh'),  # 2層目
        Dense(10, activation='tanh'),  # 3層目
        Dense(10, activation='tanh'),  # 4層目
        Dense(1, activation='linear')  # 出力層
    ])
    model.compile(optimizer=Adam(learning_rate=0.01), loss='mse')  # MSE最適化
    return model

# ---- 並列学習用の関数 ----
def train_and_evaluate(seed):
    np.random.seed(seed)
    tf.random.set_seed(seed)
    
    model = create_model()
    
    # 1000エポックずつ学習し、途中結果を保存
    best_loss = float("inf")
    best_model = None
    
    for _ in range(5):  # 1000エポック × 5回 = 5000エポック
        model.fit(X_train, y_train, epochs=1000, batch_size=32, verbose=0)
        loss = model.evaluate(X_test, y_test, verbose=0)
        
        if loss < best_loss:
            best_loss = loss
            best_model = model.get_weights()
    
    return best_loss, best_model

# ---- 並列学習の実行 ----
num_parallel = 4  # 並列計算の数
results = Parallel(n_jobs=num_parallel)(delayed(train_and_evaluate)(i) for i in range(num_parallel))

# 最適なモデルを選択
best_loss, best_weights = min(results, key=lambda x: x[0])

# ---- 最適モデルの評価 ----
final_model = create_model()
final_model.set_weights(best_weights)

y_pred = final_model.predict(X_test)

# ---- 結果のプロット ----
plt.scatter(X_test, y_test, label="True", color='blue', alpha=0.5)
plt.scatter(X_test, y_pred, label="Predicted", color='red', alpha=0.5)
plt.xlabel("x")
plt.ylabel("sin(x)")
plt.title("Neural Network Approximation of Sin(x)")
plt.legend()
plt.show()
