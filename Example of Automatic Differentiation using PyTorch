import numpy as np
import torch

# 数値微分の例 / Example of Numerical Differentiation

# 例: f(x, y) = x^2 + y^2 の偏微分 / Example function f(x, y) = x^2 + y^2
def f(x, y):
    return x**2 + y**2

# 点 (x, y) = (1.0, 2.0) における f の偏微分を計算 / Compute partial derivatives of f at (x, y) = (1.0, 2.0)
x_num = 1.0
y_num = 2.0
h = 1e-5  # 微小変化量 / Small step size

# 数値微分による偏微分の近似 / Approximate partial derivatives using numerical differentiation
df_dx_num = (f(x_num + h, y_num) - f(x_num, y_num)) / h  # ∂f/∂x
df_dy_num = (f(x_num, y_num + h) - f(x_num, y_num)) / h  # ∂f/∂y

print("Numerical Differentiation:")
print(f"∂f/∂x at (x, y) = (1.0, 2.0): {df_dx_num}")
print(f"∂f/∂y at (x, y) = (1.0, 2.0): {df_dy_num}\n")

# 自動微分の例 / Example of Automatic Differentiation using PyTorch

# xとyをテンソルとして定義し、勾配を追跡するように設定 / Define x and y as tensors with gradient tracking
x_auto = torch.tensor(1.0, requires_grad=True)
y_auto = torch.tensor(2.0, requires_grad=True)

# 関数の計算 / Compute the function using tensors
z_auto = f(x_auto, y_auto)

# zの勾配を計算 / Compute gradients of z with respect to x and y
z_auto.backward()

# 自動微分による偏微分の結果を表示 / Display results of automatic differentiation
df_dx_auto = x_auto.grad
df_dy_auto = y_auto.grad

print("Automatic Differentiation with PyTorch:")
print(f"∂f/∂x at (x, y) = (1.0, 2.0): {df_dx_auto}")
print(f"∂f/∂y at (x, y) = (1.0, 2.0): {df_dy_auto}")
