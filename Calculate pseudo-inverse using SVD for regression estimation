import numpy as np
import matplotlib.pyplot as plt
from scipy.stats import multivariate_normal

# データ生成（重回帰分析用）/ Generate data for multiple regression
np.random.seed(42)
n_samples = 100
X = np.random.randn(n_samples, 3)  # 3つの独立変数 / 3 independent variables
true_beta = np.array([2, -1, 3])  # 真の回帰係数 / True regression coefficients
y = X @ true_beta + np.random.randn(n_samples) * 0.5  # ノイズ付きの従属変数 / Dependent variable with noise

# SVDを使って擬似逆行列を計算し、重回帰分析の推定量を求める / Calculate pseudo-inverse using SVD for regression estimation
U, S, Vt = np.linalg.svd(X, full_matrices=False)
Sigma_pinv = np.diag(1 / S)  # Σ^+ を計算 / Compute Σ^+
X_pinv = Vt.T @ Sigma_pinv @ U.T  # 擬似逆行列 X^+ = V Σ^+ U^T / Pseudo-inverse calculation
beta_hat = X_pinv @ y

print("Estimated coefficients (beta_hat using SVD):", beta_hat)

# NumPyを用いた最小二乗推定量との比較 / Compare with least squares estimation using NumPy
beta_hat_np = np.linalg.pinv(X) @ y
print("\nEstimated coefficients (beta_hat using NumPy's pinv):", beta_hat_np)

# 多変量正規分布の生成 / Generate samples from a multivariate normal distribution
mean = np.array([0, 0])  # 平均ベクトル / Mean vector
cov = np.array([[1, 0.5], [0.5, 1]])  # 共分散行列 / Covariance matrix
data = np.random.multivariate_normal(mean, cov, 500)

# 多変量正規分布のプロット / Plot samples from multivariate normal distribution
plt.figure(figsize=(6, 6))
plt.scatter(data[:, 0], data[:, 1], alpha=0.5, label='Samples from Multivariate Normal')
plt.xlabel('X1')
plt.ylabel('X2')
plt.title('Samples from Multivariate Normal Distribution')
plt.grid(True)
plt.axis('equal')
plt.legend()
plt.show()

# 変分自由エネルギーの計算 / Calculate variational free energy
# ここでは、簡単な例として、データ点の分布と多変量正規分布のKLダイバージェンスを計算します
# Here, as a simple example, we calculate the KL divergence between the data distribution and a multivariate normal distribution
mu_q = np.mean(data, axis=0)  # q(x) の平均（データの平均）/ Mean of q(x) (mean of the data)
cov_q = np.cov(data.T)  # q(x) の共分散行列（データの共分散）/ Covariance matrix of q(x) (covariance of the data)

# p(x) は与えられた平均と共分散を持つ分布 / p(x) is a distribution with the given mean and covariance
p = multivariate_normal(mean=mean, cov=cov)

# 変分自由エネルギーとして、データ点に対する対数尤度を計算（簡単な例）/ Calculate log-likelihood of the data under p(x) as variational free energy (simple example)
log_likelihood = np.mean(p.logpdf(data))
kl_divergence = np.trace(np.linalg.inv(cov) @ cov_q) + (mu_q - mean).T @ np.linalg.inv(cov) @ (mu_q - mean) - data.shape[1] + np.log(np.linalg.det(cov) / np.linalg.det(cov_q))

print("\nLog-Likelihood of data under p(x):", log_likelihood)
print("KL Divergence between q(x) and p(x):", kl_divergence)

# 変分自由エネルギーの近似として、ELBO (Evidence Lower Bound) を計算 / Calculate ELBO (Evidence Lower Bound) as an approximation of variational free energy
elbo = log_likelihood - kl_divergence
print("\nApproximate Variational Free Energy (ELBO):", elbo)
