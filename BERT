# Install necessary libraries (if not installed)
# !pip install transformers
# !pip install torch

import torch
from transformers import BertTokenizer, BertForSequenceClassification

# Load pre-trained BERT tokenizer and model
tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')
model = BertForSequenceClassification.from_pretrained('bert-base-uncased')

# Sample text to classify
texts = ["Hello, how are you?", "BERT is a powerful transformer model."]

# Tokenize the input text (convert text to token IDs)
inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)

# Forward pass: get the output from the model
with torch.no_grad():  # Disable gradient calculation for inference
    outputs = model(**inputs)

# Get the logits (raw predictions)
logits = outputs.logits

# Convert logits to probabilities using softmax (for classification)
probabilities = torch.nn.functional.softmax(logits, dim=-1)

# Print the raw logits and probabilities for each class
print("Logits: ", logits)
print("Probabilities: ", probabilities)

# Example: For binary classification (0 or 1)
predictions = torch.argmax(probabilities, dim=-1)
print("Predictions (0 or 1):", predictions)
