import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_iris
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
import random

# ---------------------------------
# 教師あり学習: K-近傍法 (Supervised Learning: K-Nearest Neighbors)
# ---------------------------------
def supervised_learning():
    # Irisデータセットのロード / Load the Iris dataset
    iris = load_iris()
    X = iris.data  # 特徴量 / Features
    y = iris.target  # ラベル / Labels

    # データの分割 / Split the data
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

    # KNNモデルのインスタンス化 / Instantiate the KNN model
    knn = KNeighborsClassifier(n_neighbors=3)

    # モデルのトレーニング / Train the model
    knn.fit(X_train, y_train)

    # テストデータに対する予測 / Make predictions on the test data
    y_pred = knn.predict(X_test)
    
    # 結果の表示 / Display results
    print("Supervised Learning (KNN):")
    print("Predicted labels:", y_pred)  # 予測されたラベル / Predicted labels
    print("True labels:", y_test)  # 実際のラベル / True labels

# ---------------------------------
# 教師なし学習: K-meansクラスタリング (Unsupervised Learning: K-means Clustering)
# ---------------------------------
def unsupervised_learning():
    # サンプルデータの生成 / Generate sample data
    from sklearn.datasets import make_blobs
    X, y_true = make_blobs(n_samples=300, centers=4, cluster_std=0.60, random_state=0)

    # K-meansモデルのインスタンス化 / Instantiate the K-means model
    kmeans = KMeans(n_clusters=4)

    # モデルのフィッティング / Fit the model
    y_kmeans = kmeans.fit_predict(X)

    # クラスタリング結果の可視化 / Visualize the clustering results
    plt.figure(figsize=(8, 5))
    plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')  # クラスタごとに色をつけて散布図を作成 / Create scatter plot colored by clusters
    centers = kmeans.cluster_centers_  # セントロイドの取得 / Get the centroids
    plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.75, marker='X')  # セントロイドのプロット / Plot the centroids
    plt.title('Unsupervised Learning (K-means)')
    plt.xlabel('Feature 1')
    plt.ylabel('Feature 2')
    plt.show()

# ---------------------------------
# 強化学習: 簡単なQ-learningの実装 (Reinforcement Learning: Simple Q-learning Implementation)
# ---------------------------------
def reinforcement_learning():
    # 環境の設定 / Set up the environment
    n_states = 5  # 状態の数 / Number of states
    n_actions = 2  # 行動の数 / Number of actions
    Q = np.zeros((n_states, n_actions))  # Qテーブルの初期化 / Initialize Q-table
    learning_rate = 0.1  # 学習率 / Learning rate
    discount_factor = 0.9  # 割引率 / Discount factor
    episodes = 100  # エピソードの数 / Number of episodes

    for episode in range(episodes):
        state = random.randint(0, n_states - 1)  # ランダムに初期状態を選択 / Randomly choose an initial state
        done = False  # エピソードの終了フラグ / Flag to check if episode is done
        
        while not done:
            action = np.argmax(Q[state])  # Qテーブルに基づく行動の選択 / Choose action based on Q-table
            next_state = (state + 1) % n_states  # 次の状態を設定 / Set the next state
            
            # 報酬の設定 / Set the reward
            reward = 1 if next_state == 0 else 0  # 次の状態が0なら報酬1、そうでなければ0 / Reward is 1 if next state is 0, else 0
            
            # Q値の更新 / Update Q-value
            Q[state, action] += learning_rate * (reward + discount_factor * np.max(Q[next_state]) - Q[state, action])
            
            state = next_state  # 状態を更新 / Update the state
            
            if state == 0:  # 状態が0になったらエピソード終了 / End episode if state is 0
                done = True

    print("Reinforcement Learning (Q-learning):")
    print("Learned Q-table:\n", Q)  # 学習したQテーブルの表示 / Display the learned Q-table

# メイン関数 / Main function
if __name__ == "__main__":
    # 教師あり学習の実行 / Run supervised learning
    supervised_learning()
    
    # 教師なし学習の実行 / Run unsupervised learning
    unsupervised_learning()
    
    # 強化学習の実行 / Run reinforcement learning
    reinforcement_learning()
