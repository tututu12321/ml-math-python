import tensorflow as tf
from tensorflow.keras import layers
import matplotlib.pyplot as plt
import numpy as np

# ランダムノイズ（潜在空間）
def build_generator():
    model = tf.keras.Sequential()
    model.add(layers.Dense(128, activation='relu', input_dim=100))
    model.add(layers.BatchNormalization())
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.BatchNormalization())
    model.add(layers.Dense(512, activation='relu'))
    model.add(layers.BatchNormalization())
    model.add(layers.Dense(1024, activation='relu'))
    model.add(layers.BatchNormalization())
    model.add(layers.Dense(28*28*1, activation='tanh'))  # 28x28の画像を生成
    model.add(layers.Reshape((28, 28, 1)))
    return model

def build_discriminator():
    model = tf.keras.Sequential()
    model.add(layers.Flatten(input_shape=(28, 28, 1)))
    model.add(layers.Dense(1024, activation='relu'))
    model.add(layers.Dense(512, activation='relu'))
    model.add(layers.Dense(256, activation='relu'))
    model.add(layers.Dense(1, activation='sigmoid'))  # 0か1を予測
    return model

# GANの本体
def build_gan(generator, discriminator):
    discriminator.trainable = False
    model = tf.keras.Sequential()
    model.add(generator)
    model.add(discriminator)
    return model

# モデルのコンパイル
def compile_models(generator, discriminator, gan):
    discriminator.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    gan.compile(loss='binary_crossentropy', optimizer='adam')

# トレーニングループ
def train_gan(generator, discriminator, gan, epochs=1, batch_size=128):
    # MNISTデータセットの読み込み
    (x_train, _), (_, _) = tf.keras.datasets.mnist.load_data()
    x_train = x_train / 127.5 - 1.0  # ピクセルを[-1, 1]にスケーリング
    x_train = np.expand_dims(x_train, axis=-1)  # (28, 28, 1)の形に変換

    batch_count = x_train.shape[0] // batch_size

    for epoch in range(epochs):
        for _ in range(batch_count):
            # 本物の画像をランダムに選択
            real_images = x_train[np.random.randint(0, x_train.shape[0], batch_size)]
            real_labels = np.ones((batch_size, 1))  # 本物の画像ラベルは1

            # 偽の画像を生成
            noise = np.random.normal(0, 1, (batch_size, 100))  # ノイズから画像を生成
            fake_images = generator.predict(noise)
            fake_labels = np.zeros((batch_size, 1))  # 偽の画像ラベルは0

            # 判別器のトレーニング
            d_loss_real = discriminator.train_on_batch(real_images, real_labels)
            d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)
            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)

            # ジェネレータのトレーニング
            noise = np.random.normal(0, 1, (batch_size, 100))  # 再度ランダムノイズ
            valid_labels = np.ones((batch_size, 1))  # ジェネレータは本物の画像を生成することを目指す
            g_loss = gan.train_on_batch(noise, valid_labels)

        # エポック毎の進捗表示
        print(f"Epoch: {epoch}, D Loss: {d_loss[0]}, G Loss: {g_loss}")

        # 一定の間隔で画像を生成
        if epoch % 10 == 0:
            generate_and_plot(generator, epoch)

# 生成した画像をプロット
def generate_and_plot(generator, epoch):
    noise = np.random.normal(0, 1, (16, 100))  # 16枚の画像を生成
    generated_images = generator.predict(noise)
    plt.figure(figsize=(4, 4))
    for i in range(generated_images.shape[0]):
        plt.subplot(4, 4, i+1)
        plt.imshow(generated_images[i, :, :, 0], cmap='gray')
        plt.axis('off')
    plt.tight_layout()
    plt.savefig(f"generated_image_epoch_{epoch}.png")
    plt.show()

# モデルの作成
generator = build_generator()
discriminator = build_discriminator()
gan = build_gan(generator, discriminator)

# モデルのコンパイル
compile_models(generator, discriminator, gan)

# GANのトレーニング
train_gan(generator, discriminator, gan, epochs=100, batch_size=128)
