import numpy as np
import matplotlib.pyplot as plt
from sklearn.linear_model import LinearRegression
from sklearn.preprocessing import PolynomialFeatures
from sklearn.metrics import mean_squared_error

# Function a(n)
def a_n(n):
    return 3 * n**2 - 4 * n + 3

# Generate n values from 1 to 100
n = np.arange(1, 101)
y = a_n(n)

# Polynomial fit (2nd degree)
coeffs = np.polyfit(n, y, 2)
poly_fit = np.polyval(coeffs, n)

# Polynomial regression (overfitting: degree 10)
poly_features = PolynomialFeatures(degree=10)
n_poly = poly_features.fit_transform(n.reshape(-1, 1))

model = LinearRegression()
model.fit(n_poly, y)
y_poly_reg = model.predict(n_poly)

# Calculate MSE for comparison
mse_poly_fit = mean_squared_error(y, poly_fit)
mse_poly_reg = mean_squared_error(y, y_poly_reg)

# Plotting the results
plt.figure(figsize=(10, 6))

# Plot original data and polynomial fit (2nd degree)
plt.plot(n, y, label="Actual data (a(n))", color='blue')
plt.plot(n, poly_fit, label="Polynomial Fit (degree 2)", color='green')

# Plot polynomial regression (overfitting, degree 10)
plt.plot(n, y_poly_reg, label="Polynomial Regression (degree 10)", color='red', linestyle='dashed')

# Adding labels and title
plt.xlabel('n')
plt.ylabel('a(n)')
plt.title('Fitting and Overfitting Comparison')
plt.legend()

# Display the plot
plt.grid(True)
plt.show()

# Output Mean Squared Errors (MSE) for comparison
print(f'MSE of Polynomial Fit (degree 2): {mse_poly_fit}')
print(f'MSE of Polynomial Regression (degree 10): {mse_poly_reg}')
