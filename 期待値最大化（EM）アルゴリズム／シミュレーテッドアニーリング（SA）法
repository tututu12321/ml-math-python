import numpy as np
import scipy.stats as stats
import random

def em_algorithm(data, num_clusters, max_iter=100, tol=1e-6):
    """
    期待値最大化（EM）アルゴリズムでガウス混合モデル（GMM）を最適化。
    """
    n_samples = len(data)
    np.random.seed(42)
    
    # 初期化: 平均、分散、混合比率
    means = np.random.choice(data, num_clusters)
    variances = np.full(num_clusters, np.var(data))
    weights = np.full(num_clusters, 1 / num_clusters)
    
    for iteration in range(max_iter):
        # Eステップ: 負担率を計算
        responsibilities = np.zeros((n_samples, num_clusters))
        for k in range(num_clusters):
            responsibilities[:, k] = weights[k] * stats.norm.pdf(data, means[k], np.sqrt(variances[k]))
        responsibilities /= responsibilities.sum(axis=1, keepdims=True)
        
        # Mステップ: パラメータ更新
        Nk = responsibilities.sum(axis=0)
        new_means = (responsibilities * data[:, np.newaxis]).sum(axis=0) / Nk
        new_variances = (responsibilities * (data[:, np.newaxis] - new_means) ** 2).sum(axis=0) / Nk
        new_weights = Nk / n_samples
        
        # 収束判定
        if np.linalg.norm(new_means - means) < tol:
            break
        
        means, variances, weights = new_means, new_variances, new_weights
    
    return means, variances, weights

def simulated_annealing(data, num_clusters, initial_temp=100, cooling_rate=0.99, max_iter=100):
    """
    シミュレーテッドアニーリング（SA）法を用いてEMの初期値を最適化
    """
    best_means = np.random.choice(data, num_clusters)
    best_score = np.inf
    temp = initial_temp
    
    for iteration in range(max_iter):
        candidate_means = best_means + np.random.normal(0, 0.1, num_clusters)  # ランダム摂動
        _, _, weights = em_algorithm(data, num_clusters)  # EM実行
        score = -np.sum(weights * np.log(weights))  # エントロピー最小化（擬似評価関数）
        
        if score < best_score or np.exp((best_score - score) / temp) > np.random.rand():
            best_means = candidate_means
            best_score = score
        
        temp *= cooling_rate  # 温度を減衰
    
    return best_means

# データ生成（ガウス分布 2クラスタ）
np.random.seed(42)
data = np.concatenate([np.random.normal(-2, 1, 100), np.random.normal(3, 1, 100)])

# SAで初期値を最適化
optimized_means = simulated_annealing(data, num_clusters=2)

# EMでクラスタリング
final_means, final_variances, final_weights = em_algorithm(data, num_clusters=2)

# 結果出力
print(f"最適化された初期値: {optimized_means}")
print(f"最終的な平均: {final_means}")
print(f"最終的な分散: {final_variances}")
print(f"最終的な混合比率: {final_weights}")
