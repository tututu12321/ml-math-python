import numpy as np
import torch

# **チェーンルールの確認**
# f(x) = sin(x^2)
# g(x) = x^2
# f'(x) = cos(x^2) * 2x （チェーンルール適用）

def f(x):
    return np.sin(x**2)

def df_dx(x):
    return np.cos(x**2) * 2 * x

x = np.linspace(-2, 2, 100)
y = f(x)
dy_dx = df_dx(x)

# **誤差伝播法（バックプロパゲーション）による計算**
x_tensor = torch.tensor(x, dtype=torch.float32, requires_grad=True)
y_tensor = torch.sin(x_tensor**2)
y_tensor.backward(torch.ones_like(x_tensor))

dy_dx_torch = x_tensor.grad.numpy()

# **プロット**
import matplotlib.pyplot as plt

plt.figure(figsize=(8, 5))
plt.plot(x, dy_dx, label="Analytical Derivative", linestyle='dashed')
plt.plot(x, dy_dx_torch, label="Backprop Derivative", linestyle='solid')
plt.xlabel("x")
plt.ylabel("df/dx")
plt.title("Chain Rule and Backpropagation")
plt.legend()
plt.show()
